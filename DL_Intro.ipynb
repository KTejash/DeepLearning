{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPufQ3XBMIaM/qL9dDf3dgc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShubhamP1028/DeepLearningTute/blob/main/DL_Intro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction to Deep Learning\n",
        "\n",
        "### What is Deep learning? -\n",
        "Deep learning is a type or a subfield of Machine learning. Which woorks majorly on multiple(deep) hidden layers thus justifying its name.\n",
        "In deep learning we use logical structure similar to neurons in our brains called Neural Network. The most basic component of neural network is called Perceptron (Neutron).\n",
        "\n",
        "### Difference between AI, ML and DL.\n",
        "<b>AI : </b> is a broader term meaning to creation of a system to generate an intelligent machine which has intellignce similar to humans. Components or types of AI systems -\n",
        "\n",
        "*  Expert systems (Complex and multilayered If - Else rules)\n",
        "*  Machine Learning\n",
        "*  NLP\n",
        "*  Robotics\n",
        "\n",
        "\n",
        "<b>Machine learning :</b> is a subset of AI, which is dependent of statistical techniques for prediction and classification functions.\n",
        "\n",
        "<b>Deep learning :</b> is a subst of ML, which uses multiple basic machine learning models and then uses deep hidden layer for processing using complex logical structure and mathematics to define the output.\n",
        "\n",
        "\n",
        "### What are Neurons?\n",
        "Neurons or Perceptrons in Deep learning neural networks are basic ML models, which are used as fundamental blocks of neural networks.\n",
        "\n",
        "structure of neuron is like: Inputs ➡️ Neuron ➡️ Output\n",
        "here neuron is processing unit and consist of weight and bias parameter and activation function for processing to get output.\n",
        "Eq. y = f(∑(wᵢxᵢ) + b) ⟺  y = w1x1 + w2x2 + ....wnxn + b\n",
        "\n",
        "### What is Activation function?\n",
        "Activation function is a key component used in neural networks to introduce non-linearity to the model so that it can be more flexible and more creative in processing and prediction.\n",
        "\n",
        "### What are Parameters?\n",
        "Parameters are user defined inputs given to the model while development that are essential for processing done by neurons.\n",
        "*  Weights - values that define importance or influence of an neuron on all other neurons.\n",
        "*  Bias - Constant added to neuron's weighted input to better learn and provide mechanism to recognise patterns.\n",
        "\n"
      ],
      "metadata": {
        "id": "9lpD2lq3Viwn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CPI9adSYVZY7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### First neuron From Scratch\n",
        "neuron features -\n",
        "*  2 inputs\n",
        "*  manually defined weight and bias\n",
        "*  activation function - Sigmoid\n",
        "\n",
        "Sigmoid - f(x) = 1/(1+e^-x)"
      ],
      "metadata": {
        "id": "7tnTBp97xw3N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Activation function\n",
        "import numpy as np\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def tanh(x):\n",
        "    return (np.exp(x) - np.exp(-x)) / (np.exp(x) + np.exp(-x))\n",
        "\n",
        "def relu(x):\n",
        "    return np.maximum(0, x)\n",
        "\n",
        "def leaky_relu(x):\n",
        "    return np.maximum(0.01*x, x)"
      ],
      "metadata": {
        "id": "ZIpLKEFEx1Su"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Equation of Neuron : y = a(w1x1 + w2c2 + b)"
      ],
      "metadata": {
        "id": "HL-H7piwzOvl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# inputs\n",
        "x1= 0.5\n",
        "x2=0.8\n",
        "# weight\n",
        "w1=0.4\n",
        "w2=0.7\n",
        "# bias\n",
        "b= -0.2\n",
        "\n",
        "y = w1*x1 + w2*x2 + b\n",
        "sig_opt = sigmoid(y)\n",
        "print('Sigmoid output :',sig_opt)\n",
        "\n",
        "tanh_opt = tanh(y)\n",
        "print('Tanh output :',tanh_opt)\n",
        "\n",
        "relu_opt = relu(y)\n",
        "print('ReLU output :',relu_opt)\n",
        "\n",
        "leaky_relu_opt = leaky_relu(y)\n",
        "print('Leaky ReLU output :',leaky_relu_opt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i88uCEnzyxUU",
        "outputId": "4a2cb10c-9c7b-46a4-a392-e0cce9ea2885"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sigmoid output : 0.6364525402815664\n",
            "Tanh output : 0.5079774328978962\n",
            "ReLU output : 0.56\n",
            "Leaky ReLU output : 0.56\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def neuron_output(x1, x2, w1, w2, bias):\n",
        "    activation = input('Enter activation function to use: ')\n",
        "    activation = activation.strip().lower()\n",
        "\n",
        "    y = w1*x1 + w2*x2 + bias\n",
        "    if activation == 'sigmoid':\n",
        "        return sigmoid(y)\n",
        "\n",
        "    elif activation == 'tanh':\n",
        "        return tanh(y)\n",
        "\n",
        "    elif activation == 'relu':\n",
        "        return relu(y)\n",
        "\n",
        "    elif activation == 'leaky_relu':\n",
        "        return leaky_relu(y)"
      ],
      "metadata": {
        "id": "3csuLiLoz8oD"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q3tyUa7F1NJZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}